{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5bb6b74",
   "metadata": {},
   "source": [
    "# CedarSim Pre-Removal Analysis\n",
    "*Comprehensive Impact Analysis Before Data Cleaning*\n",
    "\n",
    "## Objectives\n",
    "1. Analyze SKUs with missing lead times (298 SKUs)\n",
    "2. Analyze unmapped SKUs (197 SKUs)\n",
    "3. Ensure 229 validation SKUs are preserved\n",
    "4. Assess business impact of data removals\n",
    "5. Generate comprehensive impact report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e1a7fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9578801a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: data\n",
      "Inventory file exists: True\n",
      "Validation file exists: True\n",
      "SKU data shape: (6372, 28)\n",
      "Demand data shape: (86411, 16)\n",
      "Validation data shape: (229, 27)\n"
     ]
    }
   ],
   "source": [
    "# Load all data sources\n",
    "data_dir = Path('data')\n",
    "inventory_file = data_dir / '2025-07-14_MDRH_Inventory_Storage_Burn_Rates_V3.xlsx'\n",
    "validation_file = data_dir / '2025-08-04_MDRH_Inventory_Safety_Stock_Sample_Items.xlsx'\n",
    "\n",
    "print(f\"Loading data from: {data_dir}\")\n",
    "print(f\"Inventory file exists: {inventory_file.exists()}\")\n",
    "print(f\"Validation file exists: {validation_file.exists()}\")\n",
    "\n",
    "# Load main inventory data\n",
    "sku_data = pd.read_excel(inventory_file, sheet_name='01. Data (Department Rollup)')\n",
    "print(f\"SKU data shape: {sku_data.shape}\")\n",
    "\n",
    "# Load historical demand data\n",
    "demand_data = pd.read_excel(inventory_file, sheet_name='02. Full Data')\n",
    "print(f\"Demand data shape: {demand_data.shape}\")\n",
    "\n",
    "# Load validation data\n",
    "validation_data = pd.read_excel(validation_file)\n",
    "print(f\"Validation data shape: {validation_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7a86a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINDING SKUs WITH MISSING LEAD TIMES ===\n",
      "Total SKUs in Department Rollup: 6,372\n",
      "SKUs with missing lead times: 298\n",
      "\n",
      "=== MISSING LEAD TIME SKUs RECORD ===\n",
      "Total SKUs to be removed: 298\n",
      "Departments affected: 20\n",
      "Suppliers affected: 35\n",
      "\n",
      "Sample of SKUs being removed:\n",
      "    Oracle Item Number                                   Item Description  \\\n",
      "254             683374                       Cannula Inner 10mm Old Style   \n",
      "274             803852             Catheter Follower Phillips Woven  16fr   \n",
      "309             803918                    Kit Cath Suction 6Fr With Glove   \n",
      "356             804011                     Support Lumbar-Sacrl Med 30-36   \n",
      "544             605852                          Fltr Air Rear Pnl Sta Sys   \n",
      "621             677644        Test Kit Alere Influenza A&B Latex Free 24T   \n",
      "643             677737  Test BinaxNow Malaria Latex Free Alere 10 per ...   \n",
      "660             714790    Kit Collection SWAB Genexpertobgyn STR 50 Tests   \n",
      "661             714803           Diagnostics, 11 Panels, Medtox Profile-V   \n",
      "662             714803           Diagnostics, 11 Panels, Medtox Profile-V   \n",
      "\n",
      "         Department Name                      Supplier Name  \\\n",
      "254     Balance Sheet CC             Medline Industries Inc   \n",
      "274     Balance Sheet CC             Medline Industries Inc   \n",
      "309     Balance Sheet CC             Medline Industries Inc   \n",
      "356     Balance Sheet CC             Medline Industries Inc   \n",
      "544  Clinical Laboratory              Diagnostica Stago Inc   \n",
      "621  Clinical Laboratory  Abbott Rapid DX North America LLC   \n",
      "643  Clinical Laboratory      Fisher Scientific Company LLC   \n",
      "660  Clinical Laboratory                            Cepheid   \n",
      "661  Clinical Laboratory      Fisher Scientific Company LLC   \n",
      "662  Clinical Laboratory      Fisher Scientific Company LLC   \n",
      "\n",
      "     Avg Daily Burn Rate     Removal_Reason         Removal_Date  \n",
      "254                 0.28  Missing Lead Time  2025-09-11 01:50:42  \n",
      "274                 0.02  Missing Lead Time  2025-09-11 01:50:42  \n",
      "309                 0.04  Missing Lead Time  2025-09-11 01:50:42  \n",
      "356                 0.00  Missing Lead Time  2025-09-11 01:50:42  \n",
      "544                 0.00  Missing Lead Time  2025-09-11 01:50:42  \n",
      "621                 0.66  Missing Lead Time  2025-09-11 01:50:42  \n",
      "643                 0.02  Missing Lead Time  2025-09-11 01:50:42  \n",
      "660                 0.00  Missing Lead Time  2025-09-11 01:50:42  \n",
      "661                 0.34  Missing Lead Time  2025-09-11 01:50:42  \n",
      "662                 0.34  Missing Lead Time  2025-09-11 01:50:42  \n",
      "\n",
      "Record saved to: missing_lead_time_skus_record.csv\n"
     ]
    }
   ],
   "source": [
    "# Find and record the 298 SKUs with missing lead times\n",
    "print(\"=== FINDING SKUs WITH MISSING LEAD TIMES ===\")\n",
    "\n",
    "print(f\"Total SKUs in Department Rollup: {len(sku_data):,}\")\n",
    "\n",
    "# Find SKUs with missing lead times\n",
    "missing_lead_time_skus = sku_data[sku_data['Avg_Lead Time'].isnull()]\n",
    "print(f\"SKUs with missing lead times: {len(missing_lead_time_skus):,}\")\n",
    "\n",
    "# Create detailed record of missing lead time SKUs\n",
    "missing_skus_record = missing_lead_time_skus[['Oracle Item Number', 'Item Description', 'Department Name', 'Supplier Name', 'Avg Daily Burn Rate']].copy()\n",
    "missing_skus_record['Removal_Reason'] = 'Missing Lead Time'\n",
    "missing_skus_record['Removal_Date'] = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(f\"\\n=== MISSING LEAD TIME SKUs RECORD ===\")\n",
    "print(f\"Total SKUs to be removed: {len(missing_skus_record)}\")\n",
    "print(f\"Departments affected: {missing_skus_record['Department Name'].nunique()}\")\n",
    "print(f\"Suppliers affected: {missing_skus_record['Supplier Name'].nunique()}\")\n",
    "\n",
    "# Show sample of SKUs being removed\n",
    "print(f\"\\nSample of SKUs being removed:\")\n",
    "print(missing_skus_record.head(10))\n",
    "\n",
    "# Save the record\n",
    "missing_skus_record.to_csv('missing_lead_time_skus_record.csv', index=False)\n",
    "print(f\"\\nRecord saved to: missing_lead_time_skus_record.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a1e59f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CLEANING DEMAND RECORDS ===\n",
      "Total demand records before cleaning: 86,411\n",
      "SKUs to remove from demand data: 298\n",
      "Demand records after removing missing lead time SKUs: 85,603\n",
      "Demand records removed: 808\n",
      "Remaining missing lead times in demand data: 0\n",
      "Cleaned demand data saved to: demand_data_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# Clean demand records by removing records for SKUs with missing lead times\n",
    "print(\"=== CLEANING DEMAND RECORDS ===\")\n",
    "\n",
    "print(f\"Total demand records before cleaning: {len(demand_data):,}\")\n",
    "\n",
    "# Get list of SKUs to remove (Oracle Item Numbers)\n",
    "skus_to_remove = missing_lead_time_skus['Oracle Item Number'].tolist()\n",
    "print(f\"SKUs to remove from demand data: {len(skus_to_remove)}\")\n",
    "\n",
    "# Remove demand records for SKUs with missing lead times\n",
    "demand_data_cleaned = demand_data[~demand_data['Oracle Item Number'].isin(skus_to_remove)]\n",
    "print(f\"Demand records after removing missing lead time SKUs: {len(demand_data_cleaned):,}\")\n",
    "print(f\"Demand records removed: {len(demand_data) - len(demand_data_cleaned):,}\")\n",
    "\n",
    "# Check for remaining missing lead times in cleaned demand data\n",
    "remaining_missing_lead_times = demand_data_cleaned['Avg_Lead Time'].isnull().sum()\n",
    "print(f\"Remaining missing lead times in demand data: {remaining_missing_lead_times}\")\n",
    "\n",
    "# Save cleaned demand data\n",
    "demand_data_cleaned.to_csv('demand_data_cleaned.csv', index=False)\n",
    "print(f\"Cleaned demand data saved to: demand_data_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a224ffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREATING CLEAN SKU INVENTORY DATA ===\n",
      "SKU data before cleaning: 6,372\n",
      "SKU data after cleaning: 6,074\n",
      "SKUs removed: 298\n",
      "Remaining missing lead times in SKU data: 0\n",
      "Cleaned SKU data saved to: sku_data_cleaned.csv\n",
      "\n",
      "=== CLEANING SUMMARY REPORT ===\n",
      "Original SKUs: 6,372\n",
      "SKUs removed (missing lead times): 298\n",
      "Clean SKUs remaining: 6,074\n",
      "Data completeness: 95.3%\n",
      "\n",
      "Original demand records: 86,411\n",
      "Demand records removed: 808\n",
      "Clean demand records remaining: 85,603\n",
      "Demand data completeness: 99.1%\n"
     ]
    }
   ],
   "source": [
    "# Create clean SKU inventory data (remove SKUs with missing lead times)\n",
    "print(\"=== CREATING CLEAN SKU INVENTORY DATA ===\")\n",
    "\n",
    "# Create clean SKU data by removing SKUs with missing lead times\n",
    "sku_data_cleaned = sku_data[sku_data['Avg_Lead Time'].notnull()].copy()\n",
    "print(f\"SKU data before cleaning: {len(sku_data):,}\")\n",
    "print(f\"SKU data after cleaning: {len(sku_data_cleaned):,}\")\n",
    "print(f\"SKUs removed: {len(sku_data) - len(sku_data_cleaned):,}\")\n",
    "\n",
    "# Verify no missing lead times remain\n",
    "remaining_missing_lead_times_sku = sku_data_cleaned['Avg_Lead Time'].isnull().sum()\n",
    "print(f\"Remaining missing lead times in SKU data: {remaining_missing_lead_times_sku}\")\n",
    "\n",
    "# Save cleaned SKU data\n",
    "sku_data_cleaned.to_csv('sku_data_cleaned.csv', index=False)\n",
    "print(f\"Cleaned SKU data saved to: sku_data_cleaned.csv\")\n",
    "\n",
    "# Generate summary report\n",
    "print(f\"\\n=== CLEANING SUMMARY REPORT ===\")\n",
    "print(f\"Original SKUs: {len(sku_data):,}\")\n",
    "print(f\"SKUs removed (missing lead times): {len(sku_data) - len(sku_data_cleaned):,}\")\n",
    "print(f\"Clean SKUs remaining: {len(sku_data_cleaned):,}\")\n",
    "print(f\"Data completeness: {len(sku_data_cleaned)/len(sku_data)*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nOriginal demand records: {len(demand_data):,}\")\n",
    "print(f\"Demand records removed: {len(demand_data) - len(demand_data_cleaned):,}\")\n",
    "print(f\"Clean demand records remaining: {len(demand_data_cleaned):,}\")\n",
    "print(f\"Demand data completeness: {len(demand_data_cleaned)/len(demand_data)*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6178ac82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREATING SIMULATION-READY EXCEL FILE ===\n",
      "Simulation-ready Excel file created: CedarSim_Simulation_Ready_Data.xlsx\n",
      "Sheets created:\n",
      "  - 01_SKU_Inventory_Clean: 6,074 SKUs\n",
      "  - 02_Demand_Data_Clean: 85,603 demand records\n",
      "  - 03_Validation_Sample: 229 validation SKUs\n",
      "  - 04_Removed_SKUs_Record: 298 removed SKUs\n",
      "\n",
      "File size: 5.59 MB\n",
      "✅ Simulation-ready data file created successfully!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create simulation-ready Excel file with clean data\n",
    "print(\"=== CREATING SIMULATION-READY EXCEL FILE ===\")\n",
    "\n",
    "# Create a new Excel file with two sheets\n",
    "output_file = 'CedarSim_Simulation_Ready_Data.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    # Sheet 1: Clean SKU Inventory Data\n",
    "    sku_data_cleaned.to_excel(writer, sheet_name='01_SKU_Inventory_Clean', index=False)\n",
    "    \n",
    "    # Sheet 2: Clean Demand Data\n",
    "    demand_data_cleaned.to_excel(writer, sheet_name='02_Demand_Data_Clean', index=False)\n",
    "    \n",
    "    # Sheet 3: Validation Data (for reference)\n",
    "    validation_data.to_excel(writer, sheet_name='03_Validation_Sample', index=False)\n",
    "    \n",
    "    # Sheet 4: Removal Record (for tracking)\n",
    "    missing_skus_record.to_excel(writer, sheet_name='04_Removed_SKUs_Record', index=False)\n",
    "\n",
    "print(f\"Simulation-ready Excel file created: {output_file}\")\n",
    "print(f\"Sheets created:\")\n",
    "print(f\"  - 01_SKU_Inventory_Clean: {len(sku_data_cleaned):,} SKUs\")\n",
    "print(f\"  - 02_Demand_Data_Clean: {len(demand_data_cleaned):,} demand records\")\n",
    "print(f\"  - 03_Validation_Sample: {len(validation_data):,} validation SKUs\")\n",
    "print(f\"  - 04_Removed_SKUs_Record: {len(missing_skus_record):,} removed SKUs\")\n",
    "\n",
    "# Verify the file was created\n",
    "import os\n",
    "if os.path.exists(output_file):\n",
    "    file_size = os.path.getsize(output_file) / (1024*1024)  # Size in MB\n",
    "    print(f\"\\nFile size: {file_size:.2f} MB\")\n",
    "    print(\"✅ Simulation-ready data file created successfully!\")\n",
    "else:\n",
    "    print(\"❌ Error creating file\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
